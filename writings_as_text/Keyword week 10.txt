Keyword: Queering (our approach)
Max Petite
11/05/25
By “queering our approach,” Hicks calls for a shift in how we study computing history, not by adding more stories of women to balance out the men, but by rethinking the categories themselves. She defines this method as “decoupling assumptions about sex and gender from seemingly unified categories like ‘men’ and ‘women,’” and as a way of questioning the “narrow heteronormativity (born out of particular classes within Anglo-American culture)” that quietly shapes what topics are considered legitimate (Hicks, 2013, p. 86). Queering, in this sense, isn’t about inclusion or representation; it’s about reorientation. It asks historians to “de-familiarize and de-center these norms” so they can notice the variations that exist within supposedly clear groups (Hicks, 2013, p. 86). Hicks argues that doing so leads to “greater theoretical sophistication in reconstructing the past,” because it exposes the instability of the very categories that organize history (Hicks, 2013, p. 86). What looks like a clear divide between male engineers and female assistants starts to blur once we stop assuming those labels explain everything. Queering our approach means staying with that blur; seeing how gender, sexuality, and power overlap in ways that don’t always line up cleanly, and letting that complexity reshape what counts as knowledge in the first place.
Queering our approach also works as a way of thinking about the stories we tell about artificial intelligence. Public conversations about AI tend to fall into two neat boxes: the practical tools we use right now, and the fantasy of a future machine mind that either liberates us or wipes us out. Those categories feel obvious, but they function the same way Hicks describes: they flatten everything into a binary that doesn’t actually capture what’s happening. When people talk about “AI becoming human” or “AI faking intelligence,” they’re already assuming there’s one stable model of thinking that machines are either approaching or failing to imitate. Queering that narrative means loosening our grip on the idea that intelligence has to look like a single, unified thing. Instead of asking whether AI is or isn’t like us, we can ask why we expect it to fit into our script in the first place. Could machine intelligence look different from human intelligence? It opens up room to see machine intelligence as multiple, partial, and shaped by context, just as Hicks wants historians to see gender and sexuality. And once you do that, the whole sentience vs. tool debate starts to look less like a real question and more like a product of the categories we’ve inherited. Queering the approach doesn’t provide a cleaner definition of AI; it simply helps us recognize how much the old definitions have been doing the thinking for us.
